{"env_info": "sys.platform: linux\nPython: 3.9.23 (main, Jun  5 2025, 13:40:20) [GCC 11.2.0]\nCUDA available: True\nGPU 0: NVIDIA GeForce RTX 3090\nCUDA_HOME: /usr/local/cuda-11.3\nNVCC: Cuda compilation tools, release 11.3, V11.3.58\nGCC: gcc (Ubuntu 11.4.0-2ubuntu1~20.04) 11.4.0\nPyTorch: 1.13.1\nPyTorch compiling details: PyTorch built with:\n  - GCC 9.3\n  - C++ Version: 201402\n  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.7\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n  - CuDNN 8.5\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\nTorchVision: 0.14.1\nOpenCV: 4.11.0\nMMCV: 1.7.0\nMMCV Compiler: GCC 9.3\nMMCV CUDA Compiler: 11.7\nMMDetection: 2.25.1+", "config": "dataset_type = 'PanopticSceneGraphDataset'\nann_file = './data/psg/psg.json'\ncoco_root = './data/coco'\nseg_root = './data/coco/annotations'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='LoadPanopticSceneGraphAnnotations',\n        with_bbox=True,\n        with_rel=True,\n        with_mask=True,\n        with_seg=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='AutoAugment',\n        policies=[[{\n            'type':\n            'Resize',\n            'img_scale': [(480, 800), (512, 800), (544, 800), (576, 800),\n                          (608, 800), (640, 800), (672, 800), (704, 800),\n                          (736, 800), (768, 800), (800, 800)],\n            'multiscale_mode':\n            'value',\n            'keep_ratio':\n            True\n        }],\n                  [{\n                      'type': 'Resize',\n                      'img_scale': [(400, 800), (500, 800), (600, 800)],\n                      'multiscale_mode': 'value',\n                      'keep_ratio': True\n                  }, {\n                      'type': 'RelRandomCrop',\n                      'crop_type': 'absolute_range',\n                      'crop_size': (384, 600),\n                      'allow_negative_crop': False\n                  }, {\n                      'type':\n                      'Resize',\n                      'img_scale': [(480, 800), (512, 800), (544, 800),\n                                    (576, 800), (608, 800), (640, 800),\n                                    (672, 800), (704, 800), (736, 800),\n                                    (768, 800), (800, 800)],\n                      'multiscale_mode':\n                      'value',\n                      'override':\n                      True,\n                      'keep_ratio':\n                      True\n                  }]]),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=1),\n    dict(type='RelsFormatBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'gt_bboxes', 'gt_labels', 'gt_rels', 'gt_masks'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadSceneGraphAnnotations', with_bbox=True, with_rel=True),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(640, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=1),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='ToTensor', keys=['gt_bboxes', 'gt_labels']),\n            dict(\n                type='ToDataContainer',\n                fields=({\n                    'key': 'gt_bboxes'\n                }, {\n                    'key': 'gt_labels'\n                })),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=1,\n    workers_per_gpu=1,\n    train=dict(\n        type='PanopticSceneGraphDataset',\n        ann_file='./data/psg/psg.json',\n        img_prefix='./data/coco',\n        seg_prefix='./data/coco/annotations',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='LoadPanopticSceneGraphAnnotations',\n                with_bbox=True,\n                with_rel=True,\n                with_mask=True,\n                with_seg=True),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='AutoAugment',\n                policies=[[{\n                    'type':\n                    'Resize',\n                    'img_scale': [\n                        (480, 800), (512, 800), (544, 800), (576, 800),\n                        (608, 800), (640, 800), (672, 800), (704, 800),\n                        (736, 800), (768, 800), (800, 800)\n                    ],\n                    'multiscale_mode':\n                    'value',\n                    'keep_ratio':\n                    True\n                }],\n                          [{\n                              'type': 'Resize',\n                              'img_scale': [(400, 800), (500, 800),\n                                            (600, 800)],\n                              'multiscale_mode': 'value',\n                              'keep_ratio': True\n                          }, {\n                              'type': 'RelRandomCrop',\n                              'crop_type': 'absolute_range',\n                              'crop_size': (384, 600),\n                              'allow_negative_crop': False\n                          }, {\n                              'type':\n                              'Resize',\n                              'img_scale': [(480, 800), (512, 800), (544, 800),\n                                            (576, 800), (608, 800), (640, 800),\n                                            (672, 800), (704, 800), (736, 800),\n                                            (768, 800), (800, 800)],\n                              'multiscale_mode':\n                              'value',\n                              'override':\n                              True,\n                              'keep_ratio':\n                              True\n                          }]]),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=1),\n            dict(type='RelsFormatBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_rels', 'gt_masks'])\n        ],\n        split='train',\n        all_bboxes=True),\n    val=dict(\n        type='PanopticSceneGraphDataset',\n        ann_file='./data/psg/psg.json',\n        img_prefix='./data/coco',\n        seg_prefix='./data/coco/annotations',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='LoadSceneGraphAnnotations',\n                with_bbox=True,\n                with_rel=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=1),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='ToTensor', keys=['gt_bboxes', 'gt_labels']),\n                    dict(\n                        type='ToDataContainer',\n                        fields=({\n                            'key': 'gt_bboxes'\n                        }, {\n                            'key': 'gt_labels'\n                        })),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ],\n        split='test',\n        all_bboxes=True),\n    test=dict(\n        type='PanopticSceneGraphDataset',\n        ann_file='./data/psg/psg.json',\n        img_prefix='./data/coco',\n        seg_prefix='./data/coco/annotations',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='LoadSceneGraphAnnotations',\n                with_bbox=True,\n                with_rel=True),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(640, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=1),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='ToTensor', keys=['gt_bboxes', 'gt_labels']),\n                    dict(\n                        type='ToDataContainer',\n                        fields=({\n                            'key': 'gt_bboxes'\n                        }, {\n                            'key': 'gt_labels'\n                        })),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ],\n        split='test',\n        all_bboxes=True),\n    pin_memory=False,\n    persistent_workers=False,\n    prefetch_factor=1)\ncheckpoint_config = dict(interval=1, max_keep_ckpts=15)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'pretrain/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth'\nresume_from = None\nworkflow = [('train', 1), ('val', 1)]\nnum_object_classes = 133\nnum_relation_classes = 56\nfind_unused_parameters = True\nmodel = dict(\n    type='PSGTr',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=False),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n    bbox_head=dict(\n        type='CrossHead3',\n        num_classes=133,\n        num_relations=56,\n        num_obj_query=100,\n        num_rel_query=100,\n        mapper='conv_tiny',\n        in_channels=[256, 512, 1024, 2048],\n        feat_channels=256,\n        out_channels=256,\n        num_transformer_feat_level=3,\n        embed_dims=256,\n        enforce_decoder_input_project=False,\n        pixel_decoder=dict(\n            type='MSDeformAttnPixelDecoder',\n            num_outs=3,\n            norm_cfg=dict(type='GN', num_groups=32),\n            act_cfg=dict(type='ReLU'),\n            encoder=dict(\n                type='DetrTransformerEncoder',\n                num_layers=6,\n                transformerlayers=dict(\n                    type='BaseTransformerLayer',\n                    attn_cfgs=dict(\n                        type='MultiScaleDeformableAttention',\n                        embed_dims=256,\n                        num_heads=8,\n                        num_levels=3,\n                        num_points=4,\n                        im2col_step=64,\n                        dropout=0.0,\n                        batch_first=False,\n                        norm_cfg=None,\n                        init_cfg=None),\n                    ffn_cfgs=dict(\n                        type='FFN',\n                        embed_dims=256,\n                        feedforward_channels=1024,\n                        num_fcs=2,\n                        ffn_drop=0.0,\n                        act_cfg=dict(type='ReLU', inplace=True)),\n                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),\n                init_cfg=None),\n            positional_encoding=dict(\n                type='SinePositionalEncoding', num_feats=128, normalize=True),\n            init_cfg=None),\n        transformer_decoder=dict(\n            type='DetrTransformerDecoder',\n            return_intermediate=False,\n            num_layers=9,\n            transformerlayers=dict(\n                type='BaseTransformerLayer',\n                attn_cfgs=dict(\n                    type='MultiheadAttention',\n                    embed_dims=256,\n                    num_heads=8,\n                    attn_drop=0.0,\n                    proj_drop=0.0,\n                    dropout_layer=None,\n                    batch_first=False),\n                ffn_cfgs=dict(\n                    embed_dims=256,\n                    feedforward_channels=2048,\n                    num_fcs=2,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    ffn_drop=0.0,\n                    dropout_layer=None,\n                    add_identity=True),\n                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',\n                                 'ffn', 'norm'))),\n        relation_decoder=dict(\n            type='DetrTransformerDecoder',\n            return_intermediate=True,\n            num_layers=6,\n            transformerlayers=dict(\n                type='BaseTransformerLayer',\n                attn_cfgs=dict(\n                    type='MultiheadAttention',\n                    embed_dims=256,\n                    num_heads=8,\n                    attn_drop=0.0,\n                    proj_drop=0.0,\n                    dropout_layer=None,\n                    batch_first=False),\n                ffn_cfgs=dict(\n                    embed_dims=256,\n                    feedforward_channels=2048,\n                    num_fcs=2,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    ffn_drop=0.1,\n                    dropout_layer=None,\n                    add_identity=True),\n                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',\n                                 'ffn', 'norm'))),\n        positional_encoding=dict(\n            type='SinePositionalEncoding', num_feats=128, normalize=True),\n        rel_cls_loss=dict(\n            type='SeesawLoss',\n            num_classes=56,\n            return_dict=True,\n            loss_weight=2.0),\n        subobj_cls_loss=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=False,\n            loss_weight=4.0,\n            reduction='mean',\n            class_weight=[\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0\n            ]),\n        importance_match_loss=dict(\n            type='BCEWithLogitsLoss', reduction='mean', loss_weight=5.0),\n        loss_cls=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=False,\n            loss_weight=2.0,\n            reduction='mean',\n            class_weight=[\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 0.1\n            ]),\n        loss_mask=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=True,\n            reduction='mean',\n            loss_weight=5.0),\n        loss_dice=dict(\n            type='DiceLoss',\n            use_sigmoid=True,\n            activate=True,\n            reduction='mean',\n            naive_dice=True,\n            eps=1.0,\n            loss_weight=5.0)),\n    train_cfg=dict(\n        id_assigner=dict(\n            type='SpeaQMatcher',\n            sub_id_cost=dict(type='ClassificationCost', weight=1.0),\n            obj_id_cost=dict(type='ClassificationCost', weight=1.0),\n            r_cls_cost=dict(type='ClassificationCost', weight=0.0)),\n        num_points=12544,\n        oversample_ratio=3.0,\n        importance_sample_ratio=0.75,\n        mask_assigner=dict(\n            type='MaskHungarianAssigner',\n            cls_cost=dict(type='ClassificationCost', weight=2.0),\n            mask_cost=dict(\n                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n            dice_cost=dict(\n                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n        sampler=dict(type='MaskPseudoSampler')),\n    test_cfg=dict(max_per_img=100))\ncustom_imports = dict(\n    imports=[\n        'pairnet.models.frameworks.psgtr', 'pairnet.models.losses.seg_losses',\n        'pairnet.datasets', 'pairnet.datasets.pipelines.loading',\n        'pairnet.datasets.pipelines.rel_randomcrop',\n        'pairnet.models.relation_heads.approaches.matcher',\n        'pairnet.models.relation_heads.pairnet_speaq_head', 'pairnet.utils'\n    ],\n    allow_failed_imports=False)\nevaluation = dict(\n    interval=100000000,\n    metric='sgdet',\n    relation_mode=True,\n    classwise=True,\n    iou_thrs=0.5,\n    detection_method='pan_seg')\noptimizer = dict(\n    type='AdamW',\n    lr=0.0001,\n    weight_decay=0.0001,\n    paramwise_cfg=dict(\n        custom_keys=dict(\n            backbone=dict(lr_mult=0.1, decay_mult=1),\n            transformer_decoder=dict(lr_mult=0.1, decay_mult=1),\n            pixel_decoder=dict(lr_mult=0.1, decay_mult=1),\n            decoder_input_projs=dict(lr_mult=0.1, decay_mult=1)),\n        norm_decay_mult=0.0))\noptimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))\nlr_config = dict(policy='step', gamma=0.5, step=[5, 10])\nrunner = dict(type='EpochBasedRunner', max_epochs=15)\nproject_name = 'ATM'\nexpt_name = 'speaq1'\nwork_dir = './work_dirs/speaq1'\nauto_scale_lr = dict(enable=True, base_batch_size=1)\nauto_resume = False\ngpu_ids = [0]\n", "seed": 10086, "exp_name": "pairnet.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0001, "memory": 3187, "data_time": 0.0634, "loss_r_cls": 7.80283, "loss_sub_cls": 20.86276, "loss_obj_cls": 19.99896, "loss_match": 6.93187, "loss": 55.59643, "grad_norm": 32.86322, "time": 0.42552}
{"mode": "val", "epoch": 1, "iter": 99, "lr": 0.0001, "memory": 3187, "data_time": 0.03639, "loss_r_cls": 7.12377, "loss_sub_cls": 20.44629, "loss_obj_cls": 20.09608, "loss_match": 6.92857, "loss": 54.59471, "time": 0.17512}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.0001, "memory": 3187, "data_time": 0.06106, "loss_r_cls": 5.97906, "loss_sub_cls": 20.44555, "loss_obj_cls": 19.99035, "loss_match": 6.92453, "loss": 53.3395, "grad_norm": 22.32132, "time": 0.37462}
{"mode": "val", "epoch": 2, "iter": 99, "lr": 0.0001, "memory": 3187, "data_time": 0.03325, "loss_r_cls": 8.04729, "loss_sub_cls": 20.41879, "loss_obj_cls": 20.04495, "loss_match": 6.92487, "loss": 55.43589, "time": 0.17316}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.0001, "memory": 3187, "data_time": 0.06196, "loss_r_cls": 5.62211, "loss_sub_cls": 21.10336, "loss_obj_cls": 20.11292, "loss_match": 6.91532, "loss": 53.7537, "grad_norm": 20.06088, "time": 0.37629}
{"mode": "val", "epoch": 3, "iter": 99, "lr": 0.0001, "memory": 3187, "data_time": 0.03442, "loss_r_cls": 7.74214, "loss_sub_cls": 21.00212, "loss_obj_cls": 20.24296, "loss_match": 6.92045, "loss": 55.90766, "time": 0.17442}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 0.0001, "memory": 3187, "data_time": 0.06727, "loss_r_cls": 5.6107, "loss_sub_cls": 21.37629, "loss_obj_cls": 20.11443, "loss_match": 6.87507, "loss": 53.97649, "grad_norm": 21.32671, "time": 0.38957}
{"mode": "val", "epoch": 4, "iter": 99, "lr": 0.0001, "memory": 3187, "data_time": 0.03321, "loss_r_cls": 6.85524, "loss_sub_cls": 20.19842, "loss_obj_cls": 20.07219, "loss_match": 6.9263, "loss": 54.05215, "time": 0.1696}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 0.0001, "memory": 3187, "data_time": 0.0651, "loss_r_cls": 5.3997, "loss_sub_cls": 20.99596, "loss_obj_cls": 20.38367, "loss_match": 6.92406, "loss": 53.70339, "grad_norm": 20.13325, "time": 0.37851}
{"mode": "val", "epoch": 5, "iter": 99, "lr": 0.0001, "memory": 3187, "data_time": 0.03427, "loss_r_cls": 7.05886, "loss_sub_cls": 20.57501, "loss_obj_cls": 20.15622, "loss_match": 6.92816, "loss": 54.71825, "time": 0.17016}
{"mode": "train", "epoch": 6, "iter": 50, "lr": 5e-05, "memory": 3187, "data_time": 0.06421, "loss_r_cls": 5.01308, "loss_sub_cls": 21.4242, "loss_obj_cls": 19.92473, "loss_match": 6.92377, "loss": 53.28579, "grad_norm": 19.60144, "time": 0.37774}
{"mode": "val", "epoch": 6, "iter": 99, "lr": 5e-05, "memory": 3187, "data_time": 0.03427, "loss_r_cls": 7.95294, "loss_sub_cls": 20.93443, "loss_obj_cls": 20.13772, "loss_match": 6.93088, "loss": 55.95597, "time": 0.17263}
{"mode": "train", "epoch": 7, "iter": 50, "lr": 5e-05, "memory": 3187, "data_time": 0.06331, "loss_r_cls": 4.25608, "loss_sub_cls": 21.06874, "loss_obj_cls": 20.09668, "loss_match": 6.93133, "loss": 52.35283, "grad_norm": 19.43635, "time": 0.37772}
{"mode": "val", "epoch": 7, "iter": 99, "lr": 5e-05, "memory": 3187, "data_time": 0.03398, "loss_r_cls": 6.72745, "loss_sub_cls": 20.60211, "loss_obj_cls": 20.11766, "loss_match": 6.95604, "loss": 54.40327, "time": 0.16975}
{"mode": "train", "epoch": 8, "iter": 50, "lr": 5e-05, "memory": 3187, "data_time": 0.06247, "loss_r_cls": 3.86657, "loss_sub_cls": 21.67715, "loss_obj_cls": 19.94563, "loss_match": 6.90067, "loss": 52.39002, "grad_norm": 22.78586, "time": 0.3773}
{"mode": "val", "epoch": 8, "iter": 99, "lr": 5e-05, "memory": 3187, "data_time": 0.03391, "loss_r_cls": 6.94782, "loss_sub_cls": 20.82255, "loss_obj_cls": 19.99042, "loss_match": 6.91838, "loss": 54.67916, "time": 0.17331}
{"mode": "train", "epoch": 9, "iter": 50, "lr": 5e-05, "memory": 3187, "data_time": 0.06371, "loss_r_cls": 3.69376, "loss_sub_cls": 21.49351, "loss_obj_cls": 20.27881, "loss_match": 6.89195, "loss": 52.35804, "grad_norm": 19.37708, "time": 0.38931}
{"mode": "val", "epoch": 9, "iter": 99, "lr": 5e-05, "memory": 3187, "data_time": 0.03267, "loss_r_cls": 7.78002, "loss_sub_cls": 20.98056, "loss_obj_cls": 20.01498, "loss_match": 6.93008, "loss": 55.70564, "time": 0.16775}
{"mode": "train", "epoch": 10, "iter": 50, "lr": 5e-05, "memory": 3187, "data_time": 0.06179, "loss_r_cls": 3.71415, "loss_sub_cls": 21.54235, "loss_obj_cls": 20.29776, "loss_match": 6.92156, "loss": 52.47582, "grad_norm": 19.41195, "time": 0.3758}
{"mode": "val", "epoch": 10, "iter": 99, "lr": 5e-05, "memory": 3187, "data_time": 0.03319, "loss_r_cls": 7.50549, "loss_sub_cls": 20.96519, "loss_obj_cls": 19.95688, "loss_match": 6.92942, "loss": 55.35697, "time": 0.17224}
{"mode": "train", "epoch": 11, "iter": 50, "lr": 3e-05, "memory": 3187, "data_time": 0.06138, "loss_r_cls": 3.31565, "loss_sub_cls": 21.83647, "loss_obj_cls": 20.2231, "loss_match": 6.9592, "loss": 52.33442, "grad_norm": 22.49935, "time": 0.37788}
{"mode": "val", "epoch": 11, "iter": 99, "lr": 3e-05, "memory": 3187, "data_time": 0.03445, "loss_r_cls": 7.42564, "loss_sub_cls": 21.06254, "loss_obj_cls": 20.27255, "loss_match": 6.92096, "loss": 55.68169, "time": 0.17856}
{"mode": "train", "epoch": 12, "iter": 50, "lr": 3e-05, "memory": 3187, "data_time": 0.06402, "loss_r_cls": 3.50779, "loss_sub_cls": 21.66301, "loss_obj_cls": 20.36323, "loss_match": 6.92246, "loss": 52.4565, "grad_norm": 24.22057, "time": 0.38221}
{"mode": "val", "epoch": 12, "iter": 99, "lr": 3e-05, "memory": 3187, "data_time": 0.03532, "loss_r_cls": 8.09968, "loss_sub_cls": 21.24891, "loss_obj_cls": 20.18206, "loss_match": 6.91471, "loss": 56.44536, "time": 0.18404}
{"mode": "train", "epoch": 13, "iter": 50, "lr": 3e-05, "memory": 3187, "data_time": 0.06084, "loss_r_cls": 3.26938, "loss_sub_cls": 22.13843, "loss_obj_cls": 20.18834, "loss_match": 6.90399, "loss": 52.50014, "grad_norm": 24.9192, "time": 0.38512}
{"mode": "val", "epoch": 13, "iter": 99, "lr": 3e-05, "memory": 3187, "data_time": 0.0335, "loss_r_cls": 8.538, "loss_sub_cls": 21.7296, "loss_obj_cls": 20.18062, "loss_match": 6.92537, "loss": 57.37358, "time": 0.17152}
{"mode": "train", "epoch": 14, "iter": 50, "lr": 3e-05, "memory": 3187, "data_time": 0.0617, "loss_r_cls": 2.93124, "loss_sub_cls": 22.63166, "loss_obj_cls": 20.31736, "loss_match": 6.92089, "loss": 52.80114, "grad_norm": 27.30466, "time": 0.38058}
{"mode": "val", "epoch": 14, "iter": 99, "lr": 3e-05, "memory": 3187, "data_time": 0.03342, "loss_r_cls": 8.99586, "loss_sub_cls": 21.58894, "loss_obj_cls": 20.33061, "loss_match": 6.92012, "loss": 57.83554, "time": 0.1705}
{"mode": "train", "epoch": 15, "iter": 50, "lr": 3e-05, "memory": 3187, "data_time": 0.06188, "loss_r_cls": 2.95232, "loss_sub_cls": 22.0477, "loss_obj_cls": 19.9654, "loss_match": 6.96499, "loss": 51.93042, "grad_norm": 30.7422, "time": 0.37734}
{"mode": "val", "epoch": 15, "iter": 99, "lr": 3e-05, "memory": 3187, "data_time": 0.0332, "loss_r_cls": 8.94718, "loss_sub_cls": 21.38564, "loss_obj_cls": 20.1837, "loss_match": 6.9548, "loss": 57.47132, "time": 0.1708}
